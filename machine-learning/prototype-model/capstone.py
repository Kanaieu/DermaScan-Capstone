# -*- coding: utf-8 -*-
"""capstone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Te1El4NEPxBSSXS2NxmzAef37grK-vjG
"""

!pip install split-folders
!pip install gdown

import os
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
import gdown
import splitfolders
import shutil
from tensorflow.keras.applications import ResNet152
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
from tqdm.notebook import tqdm
from sklearn.metrics import confusion_matrix, classification_report
from google.colab import files

shutil.rmtree("SkinDisease", ignore_errors=True)
shutil.rmtree("skin_dataset", ignore_errors=True)

from google.colab import drive
drive.mount('/content/drive')

file_id = "1NZTookxlFKAU371O3SW4KG41doDAKZej"
gdown.download(f"https://drive.google.com/uc?id={file_id}", output="dataset.zip", quiet=False)

!unzip -q dataset.zip -d skin_dataset

splitfolders.ratio(
    input="skin_dataset",           # Folder hasil unzip
    output="SkinDisease",           # Folder output untuk split
    seed=42,
    ratio=(0.7, 0.3),               # 70% train, 30% test
    move=False                      # Copy, bukan pindah file
)
os.rename("SkinDisease/val", "SkinDisease/test")

train_dir = "SkinDisease/train"
test_dir = "SkinDisease/test"

def count_images_per_split(split_path):
    total = 0
    for cls in os.listdir(split_path):
        cls_path = os.path.join(split_path, cls)
        if os.path.isdir(cls_path):
            count = len(os.listdir(cls_path))
            print(f"{cls}: {count}")
            total += count
    print(f"Total: {total}")

print("=== TRAIN ===")
count_images_per_split("SkinDisease/train")
print("\n=== TEST ===")
count_images_per_split("SkinDisease/test")

classes = [
    "Acne", "Actinic Keratosis", "Benign Tumors", "Bullous", "Candidiasis",
    "Drug Eruption", "Eczema", "Infestations/Bites", "Lichen", "Lupus",
    "Moles", "Psoriasis", "Rosacea", "Seborrheic Keratoses", "Skin Cancer",
    "Sun/Sunlight Damage", "Tinea", "Vascular Tumors", "Vasculitis", "Vitiligo",
    "Warts"
]

train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

val_datagen = ImageDataGenerator(
    rescale=1.0/255,
    validation_split=0.2
)

test_datagen = ImageDataGenerator(rescale=1.0/255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

val_generator = val_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

print(f"Number of training samples: {train_generator.samples}")
print(f"Number of validation samples: {val_generator.samples}")
print(f"Number of testing samples: {test_generator.samples}")

def show_images(generator, classes, num_images=8):
    images, labels = next(generator)
    images = images[:num_images]
    labels = labels[:num_images]

    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))
    for i in range(num_images):
        axes[i].imshow(images[i])
        axes[i].set_title(classes[np.argmax(labels[i])])
        axes[i].axis('off')
    plt.show()

show_images(train_generator, classes)

base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = True
# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
# base_model.trainable = True
# from tensorflow.keras.applications import EfficientNetB1
# base_model = EfficientNetB1(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
# base_model.trainable = True

x = base_model.output
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.5)(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.3)(x)
predictions = layers.Dense(train_generator.num_classes, activation='softmax')(x)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    verbose=1
)

checkpoint = ModelCheckpoint(
    filepath='best_model.h5',
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_accuracy',
    patience=8,
    verbose=1,
    restore_best_weights=True,
    #baseline=0.90
)

callbacks = [reduce_lr, checkpoint, early_stopping]

model = models.Model(inputs=base_model.input, outputs=predictions)
model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=10,
    callbacks=callbacks
)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r')
plt.plot(epochs, val_acc, 'b')
plt.title('Training and Validation Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(epochs, loss, 'r')
plt.plot(epochs, val_loss, 'b')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.title('Training and Validation Loss')
plt.show()

model.save("resnet_model.h5")
print("Model saved as resnet_model.h5")

model.save("model1.h5", include_optimizer=False)

# Path folder di Google Drive
save_path = '/content/drive/My Drive/best_model1.h5'

# Simpan model ke Google Drive
model.save(save_path, include_optimizer=False)
print(f"Model saved to {save_path}")

model = tf.keras.models.load_model("best_model.h5")
print("Model loaded successfully")

def predict_and_show(model, generator, class_names, num_images=5):
    images, labels = next(generator)
    predictions = model.predict(images[:num_images])
    for i in range(num_images):
        plt.imshow(images[i])
        plt.title(f"Predicted: {class_names[np.argmax(predictions[i])]}\nTrue: {class_names[np.argmax(labels[i])]}" )
        plt.axis('off')
        plt.show()

predict_and_show(model, test_generator, classes, num_images=10)

test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Accuracy on the test set: {test_accuracy * 100:.2f}%")

test_generator.reset()
preds = model.predict(test_generator, verbose=0)
preds = np.argmax(preds, axis=1)

cm = confusion_matrix(test_generator.classes, preds)
print("Confusion Matrix:")
print(cm)

print("\nClassification Report:")
print(classification_report(
    y_true=test_generator.classes,
    y_pred=preds,
    target_names=classes,
    digits=4
))